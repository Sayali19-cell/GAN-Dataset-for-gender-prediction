{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayali19-cell/GAN-Dataset-for-gender-prediction/blob/main/Gender_Prediction_using_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lx-Vw3EqUTo",
        "outputId": "315960cf-e628-4cd0-ba41-f103a46ce752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, label_dim):\n",
        "        super(TextGenerator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + label_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # Concatenate noise with gender labels\n",
        "        input_embeds = self.embedding(noise)\n",
        "        input_with_labels = torch.cat((input_embeds, labels.unsqueeze(1).repeat(1, input_embeds.size(1), 1)), dim=-1)\n",
        "        lstm_out, _ = self.lstm(input_with_labels)\n",
        "        return self.fc(lstm_out)\n"
      ],
      "metadata": {
        "id": "g-8MJqW2qb9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDiscriminator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(TextDiscriminator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc_real_fake = nn.Linear(hidden_dim, 1)\n",
        "        self.fc_gender = nn.Linear(hidden_dim, 1)  # For binary gender classification\n",
        "\n",
        "    def forward(self, text):\n",
        "        embeds = self.embedding(text)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        real_fake_output = torch.sigmoid(self.fc_real_fake(lstm_out[:, -1, :]))\n",
        "        gender_output = torch.sigmoid(self.fc_gender(lstm_out[:, -1, :]))\n",
        "        return real_fake_output, gender_output"
      ],
      "metadata": {
        "id": "kLOnaq-4qg4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "def train_gan(generator, discriminator, dataloader, num_epochs=50):\n",
        "    for epoch in range(num_epochs):\n",
        "        for real_texts, real_labels in dataloader:\n",
        "            # Step 1: Train Discriminator\n",
        "            optimizer_d.zero_grad()\n",
        "\n",
        "            # Real samples\n",
        "            real_validity, real_gender = discriminator(real_texts)\n",
        "            real_loss = criterion(real_validity, torch.ones_like(real_validity)) + criterion(real_gender, real_labels)\n",
        "\n",
        "            # Fake samples\n",
        "            noise = torch.randint(0, vocab_size, (batch_size, seq_length))\n",
        "            fake_labels = torch.randint(0, 2, (batch_size,))\n",
        "            generated_texts = generator(noise, fake_labels)\n",
        "            fake_validity, fake_gender = discriminator(generated_texts.detach())\n",
        "            fake_loss = criterion(fake_validity, torch.zeros_like(fake_validity)) + criterion(fake_gender, fake_labels)\n",
        "\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Step 2: Train Generator\n",
        "            optimizer_g.zero_grad()\n",
        "            fake_validity, fake_gender = discriminator(generated_texts)\n",
        "            g_loss = criterion(fake_validity, torch.ones_like(fake_validity)) + criterion(fake_gender, fake_labels)\n",
        "            g_loss.backward()\n",
        "            optimizer_g.step()\n",
        "\n",
        "        print(f\"Epoch {epoch}/{num_epochs} - Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")"
      ],
      "metadata": {
        "id": "0nRmkh-hqly-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the hyperparameters\n",
        "vocab_size = 30000     # Vocabulary size (you can change it based on your needs)\n",
        "embedding_dim = 128    # Size of word embeddings\n",
        "hidden_dim = 256       # Size of the hidden layer in LSTM\n",
        "label_dim = 1          # Binary gender label (0 or 1)\n",
        "seq_length = 50        # Length of each generated text sequence\n",
        "\n",
        "# Step 2: Initialize the generator\n",
        "generator = TextGenerator(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_dim=hidden_dim, label_dim=label_dim)\n",
        "\n",
        "# Step 3: Define the data generation function\n",
        "def generate_synthetic_data(generator, num_samples):\n",
        "    synthetic_texts = []\n",
        "    synthetic_labels = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        noise = torch.randint(0, vocab_size, (1, seq_length))  # Random noise as input\n",
        "        gender_label = torch.randint(0, 2, (1,))  # Random binary gender label\n",
        "        generated_text = generator(noise, gender_label)  # Generate text based on noise and gender label\n",
        "        synthetic_texts.append(generated_text)\n",
        "        synthetic_labels.append(gender_label)\n",
        "\n",
        "    return synthetic_texts, synthetic_labels\n",
        "\n",
        "# Step 4: Generate 1000 synthetic text samples\n",
        "synthetic_texts, synthetic_labels = generate_synthetic_data(generator, 1000)\n",
        "\n",
        "# Optional: You can print a sample output to check if it's working\n",
        "print(f\"Sample Generated Text: {synthetic_texts[0]}\")\n",
        "print(f\"Sample Generated Label: {synthetic_labels[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZFblGWgrmCc",
        "outputId": "6e9f651b-b6d7-4ea0-e94e-e76133d3a30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Generated Text: tensor([[[-0.0142,  0.0172,  0.0940,  ..., -0.0406,  0.0274, -0.0593],\n",
            "         [ 0.0047, -0.0125, -0.0675,  ..., -0.1168,  0.0125, -0.1397],\n",
            "         [ 0.0919, -0.0300, -0.1197,  ..., -0.1022, -0.1191, -0.0996],\n",
            "         ...,\n",
            "         [-0.0261,  0.0226, -0.0685,  ...,  0.0218,  0.0150, -0.0674],\n",
            "         [ 0.0134,  0.0607, -0.0385,  ..., -0.0683,  0.1098, -0.0821],\n",
            "         [ 0.0494,  0.0483,  0.0617,  ..., -0.0943,  0.0496, -0.1385]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "Sample Generated Label: tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame for the synthetic dataset\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'text': [text.detach().numpy() for text in synthetic_texts], # Detach tensors and convert to NumPy arrays\n",
        "    'gender': synthetic_labels\n",
        "})\n",
        "\n",
        "# Save it as a CSV file for the next phase of fine-tuning\n",
        "synthetic_df.to_csv('synthetic_gender_texts.csv', index=False)"
      ],
      "metadata": {
        "id": "u55c3b_tr_Y5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvvDhZnhHVCc2iErnX8ZFo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}